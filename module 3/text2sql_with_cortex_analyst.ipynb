{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "5v6ontkg6xf5sjzbcbpz",
   "authorId": "273899124272",
   "authorName": "JREINI",
   "authorEmail": "josh.reini@snowflake.com",
   "sessionId": "2a21b75a-af68-4d3e-8109-12da6d5f7bf9",
   "lastEditTime": 1738011940648
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6688ba9-a559-40ea-b801-c06e44499a1f",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "811e308b-0ee7-42d4-bd64-cb046f9e1d1c",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "# Build Text to SQL with Cortex Analyst\n\nIn this notebook we show how to build a text-to-sql app using Cortex Analyst."
  },
  {
   "cell_type": "markdown",
   "id": "2abde0da-eea1-4199-bb55-eb93a58c6528",
   "metadata": {
    "name": "cell28",
    "collapsed": false
   },
   "source": "Let's start with trying on our own.\n\nCan we easily just call an LLM, give it our user query and some table information, and expect it to provide us usable SQL?\n\nLet's try."
  },
  {
   "cell_type": "code",
   "id": "20f859f8-a2c5-4bda-afaf-8078ff454993",
   "metadata": {
    "language": "python",
    "name": "cell29",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import Complete\n\nuser_query = \"What is the highest daily revenue recorded in a single day in each sales region?\"\n\nnaive_text_to_sql_messages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that writes SQL to answer natural language questions. Respond with only SQL'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'All tables are in the fully qualified snowflake schema: CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.'\n                       f'The tables available that can be used by the SQL are:'\n                       f'table: daily_revenue. columns: date, product_id, region_id, revenue, cogs, forecasted_revenue, daily_forecasted_revenue, daily_profit'\n                       f'table: product. columns: product_id, product_line'\n                       f'table: region. region_id, region, state'\n                       f'Please write valid snowflake SQL to answer the user question.'\n        }\n    ]\n    \n\nsql = Complete(\"claude-3-5-sonnet\", naive_text_to_sql_messages)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0dd1e3e9-4d79-4401-bcf0-accd26d92161",
   "metadata": {
    "language": "python",
    "name": "cell27",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a175b3d0-2e1c-434a-afd8-e6beaa687afc",
   "metadata": {
    "language": "python",
    "name": "cell30",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\n\nsql_output = session.sql(sql)\n\nsql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "77632784-4619-40fd-915d-0347b105a4cf",
   "metadata": {
    "name": "cell31",
    "collapsed": false
   },
   "source": "That was an easy question and we wanted to use just one table, and we still struggled to quickly come up with the needed context and prompt engineering to generate useful SQL with a SOTA LLM. Now imagine harder questions, hundreds of tables, and the need to perform complicated JOINS.\n\nEnter: Cortex Analyst"
  },
  {
   "cell_type": "markdown",
   "id": "a09186b0-9760-4da2-b69d-cedbe4fa514b",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Create the required roles to use Cortex Analyst\n\nMake sure to add your username in Line 10!"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "USE WAREHOUSE S;\n\nUSE ROLE SECURITYADMIN;\n\nCREATE OR REPLACE ROLE cortex_user_role;\nGRANT DATABASE ROLE SNOWFLAKE.CORTEX_USER TO ROLE cortex_user_role;\n\nUSE ROLE SECURITYADMIN;\n\nGRANT ROLE cortex_user_role TO USER <user>;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2142e1fc-9fe9-4d70-bad2-9f5dd5ec76e1",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "## Create the required databases, schemas and warehouse for this example"
  },
  {
   "cell_type": "code",
   "id": "4bb4abc2-9feb-4c23-adf8-ccd04883fa82",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\n\n-- Create demo database\nCREATE OR REPLACE DATABASE cortex_analyst_demo;\n\n-- Create schema\nCREATE OR REPLACE SCHEMA cortex_analyst_demo.revenue_timeseries;\n\n-- Create warehouse\nCREATE OR REPLACE WAREHOUSE cortex_analyst_wh\n    WAREHOUSE_SIZE = 'large'\n    WAREHOUSE_TYPE = 'standard'\n    AUTO_SUSPEND = 60\n    AUTO_RESUME = TRUE\n    INITIALLY_SUSPENDED = TRUE\nCOMMENT = 'Warehouse for Cortex Analyst demo';\n\nGRANT USAGE ON WAREHOUSE cortex_analyst_wh TO ROLE cortex_user_role;\nGRANT OPERATE ON WAREHOUSE cortex_analyst_wh TO ROLE cortex_user_role;\n\nGRANT OWNERSHIP ON SCHEMA cortex_analyst_demo.revenue_timeseries TO ROLE cortex_user_role;\nGRANT OWNERSHIP ON DATABASE cortex_analyst_demo TO ROLE cortex_user_role;\n\nUSE ROLE cortex_user_role;\n\n-- Use the created warehouse\nUSE WAREHOUSE cortex_analyst_wh;\n\nUSE DATABASE cortex_analyst_demo;\nUSE SCHEMA cortex_analyst_demo.revenue_timeseries;\n\n-- Create stage for raw data\nCREATE OR REPLACE STAGE raw_data DIRECTORY = (ENABLE = TRUE);\n\n/*--\n• Fact and Dimension Table Creation\n--*/\n\n-- Fact table: daily_revenue\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.daily_revenue (\n    date DATE,\n    revenue FLOAT,\n    cogs FLOAT,\n    forecasted_revenue FLOAT,\n    product_id INT,\n    region_id INT\n);\n\n-- Dimension table: product_dim\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.product_dim (\n    product_id INT,\n    product_line VARCHAR(16777216)\n);\n\n-- Dimension table: region_dim\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.region_dim (\n    region_id INT,\n    sales_region VARCHAR(16777216),\n    state VARCHAR(16777216)\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef609d1e-66b4-41c9-bf5f-6b18abb17f41",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "There are three data files and one YAML file included in the this repository.\n\ndaily_revenue.csv\nregion.csv\nproduct.csv\nrevenue_timeseries.yaml\nYou will now upload these files to your Snowflake account and ingest the data files into the tables created in the previous step.\n\nTo upload the data files:\n\n1. Set your role to Cortex User Role\n2. Navigate to the Data tab in Snowsight, and select Add Data\n3. On the Add Data page, select Load files into a stage\n4. Select the four files that you want to upload (listed above)\n5. Select CORTEX_ANALYST_DEMO as Database, REVENUE_TIMESERIES as Schema, and RAW_DATA as Stage\n6. Click Upload\n\nLet's go check that the files were successfully uploaded to the stage. In the Snowsight UI:\n\n7. Select Data » Databases\n8. Select the CORTEX_ANALYST_DEMO database and REVENUE_TIMESERIES Schema that contain the stage\n9. Select Stages and select the RAW_DATA stage\n10. If prompted, select Enable Directory Table and the CORTEX_ANALYST_WH to refresh the directory table\n\nYou should see the four files listed in the stage."
  },
  {
   "cell_type": "markdown",
   "id": "1cb88089-b92d-4176-93ca-5d53b8673896",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "## Copy data from stage into tables"
  },
  {
   "cell_type": "code",
   "id": "2e3df00b-c40b-49fc-826b-93203f93eedf",
   "metadata": {
    "language": "sql",
    "name": "cell25",
    "collapsed": false
   },
   "outputs": [],
   "source": "USE ROLE CORTEX_USER_ROLE;\nUSE DATABASE CORTEX_ANALYST_DEMO;\nUSE SCHEMA CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES;\nUSE WAREHOUSE CORTEX_ANALYST_WH;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35b3572a-da63-4f67-a889-536bdb71086f",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "/*--\n• looad data into tables\n--*/\n\nUSE ROLE CORTEX_USER_ROLE;\nUSE DATABASE CORTEX_ANALYST_DEMO;\nUSE SCHEMA CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES;\nUSE WAREHOUSE CORTEX_ANALYST_WH;\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.DAILY_REVENUE\nFROM @raw_data\nFILES = ('daily_revenue.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n\n\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.PRODUCT_DIM\nFROM @raw_data\nFILES = ('product.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n\n\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.REGION_DIM\nFROM @raw_data\nFILES = ('region.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "31322281-80ec-4143-b611-08df10dde463",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Create a Cortex Search service to help Analyst\n\nNow, you will integrate Cortex Search as a way to improve literal string searches to help Cortex Analyst generate more accurate SQL queries. Writing the correct SQL query to answer a question sometimes requires knowing exact literal values to filter on. Since those values can't always be extracted directly from the question, a search of some kind may be needed."
  },
  {
   "cell_type": "code",
   "id": "8f4f3913-094b-411e-941d-4dd8ae08275a",
   "metadata": {
    "language": "sql",
    "name": "cell37",
    "collapsed": false
   },
   "outputs": [],
   "source": "USE DATABASE cortex_analyst_demo;\nUSE SCHEMA revenue_timeseries;\nuse ROLE cortex_user_role;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c67b082a-bdcb-4112-a93e-1a5cc6ce3604",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "USE DATABASE cortex_analyst_demo;\nUSE SCHEMA revenue_timeseries;\nuse ROLE cortex_user_role;\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE product_line_search_service\n  ON product_dimension\n  WAREHOUSE = cortex_analyst_wh\n  TARGET_LAG = '1 hour'\n  AS (\n      SELECT DISTINCT product_line AS product_dimension FROM product_dim\n  );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cabbbf20-3724-46a6-a88d-6694f3928f65",
   "metadata": {
    "name": "cell26",
    "collapsed": false
   },
   "source": "## Using 'semantic models' to share context with LLMs\n\nSemantic models give us a structured way to capture information about our data and how it relates to our business. We can pass this information to the LLM to get better SQL generation."
  },
  {
   "cell_type": "markdown",
   "id": "b70f3742-a73f-458e-b36b-0fe42344c652",
   "metadata": {
    "name": "cell32",
    "collapsed": false
   },
   "source": "adsf"
  },
  {
   "cell_type": "code",
   "id": "66dba73d-94e1-4259-9a99-445f27c5c2f1",
   "metadata": {
    "language": "python",
    "name": "cell33",
    "collapsed": false
   },
   "outputs": [],
   "source": "semantic_model = \"\"\"\"\"\"\n\nsemantic_model_name = \"\"\"\nname: Revenue\n\"\"\"\n\nsemantic_model += semantic_model_name\n\nsemantic_model_revenue = \"\"\"\ntables:\n  - name: daily_revenue\n    description: Daily total revenue, aligned with daily \"Cost of Goods Sold\" (COGS), and forecasted revenue.\n    base_table:\n      database: cortex_analyst_demo\n      schema: revenue_timeseries\n      table: daily_revenue\n    primary_key:\n      columns:\n        - date\n        - product_id\n        - region_id\n    dimensions:\n      - name: product_id\n        expr: product_id\n        data_type: number\n      - name: region_id\n        expr: region_id\n        data_type: number\n    time_dimensions:\n      - name: date\n        expr: date\n        description: date with measures of revenue, COGS, and forecasted revenue.\n        unique: true\n        data_type: date\n    measures:\n      - name: daily_revenue\n        expr: revenue\n        description: total revenue for the given day\n        synonyms: [\"sales\", \"income\"]\n        default_aggregation: sum\n        data_type: number\n      - name: daily_cogs\n        expr: cogs\n        description: total cost of goods sold for the given day\n        synonyms: [\"cost\", \"expenditures\"]\n        default_aggregation: sum\n        data_type: number\n      - name: daily_forecasted_revenue\n        expr: forecasted_revenue\n        description: total forecasted revenue for a given day\n        synonyms: [\"forecasted sales\", \"forecasted income\"]\n        default_aggregation: sum\n        data_type: number\n      - name: daily_profit\n        description: profit is the difference between revenue and expenses.\n        expr: revenue - cogs\n        data_type: number\n      - name: daily_forecast_abs_error\n        synonyms:\n          - absolute error\n          - L1\n        description: absolute error between forecasted and actual revenue\n        expr: abs(forecasted_revenue - revenue)\n        data_type: number\n        default_aggregation: avg\n\"\"\"\n\nsemantic_model += semantic_model_revenue",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ddf296f8-563e-4947-bcea-2cca1f57ab7c",
   "metadata": {
    "name": "cell41",
    "collapsed": false
   },
   "source": "Now that we've expended more effort in writing down our semantic model of the data we want to use, let's try again to 'naively' pass it to a SOTA LLM."
  },
  {
   "cell_type": "code",
   "id": "f0a08baa-381c-489d-866d-8f673f879c08",
   "metadata": {
    "language": "python",
    "name": "cell38",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import Complete\n\nuser_query = \"What is the highest daily revenue recorded in a single day in each sales region?\"\n\nnaive_text_to_sql_messages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that writes snowflake SQL to answer natural language questions. Respond with only SQL'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'All tables are in the fully qualified snowflake schema: CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.'\n                       f'{semantic_model}'\n                       f'Please write valid snowflake SQL to answer the user question, and do not include fences.'\n        }\n    ]\n    \n\nsql = Complete(\"claude-3-5-sonnet\", naive_text_to_sql_messages)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "58902f47-d70c-46e4-8927-b04739cd999f",
   "metadata": {
    "language": "python",
    "name": "cell39",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "sql",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97b08b65-2b7c-4a68-af6f-3adeb670831a",
   "metadata": {
    "language": "python",
    "name": "cell40",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "sql_output = session.sql(sql)\n\nsql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b64f8548-56a4-4022-b454-c2293b2bbcf1",
   "metadata": {
    "name": "cell43",
    "collapsed": false
   },
   "source": "This worked pretty well, but it'd be great to have the region name instead of just the ID.\n\nLet's expand the semantic model to include the region table and how to join it with the revenue table."
  },
  {
   "cell_type": "code",
   "id": "a835ccbf-2f9e-4019-bb7b-a044b9cfe0ad",
   "metadata": {
    "language": "python",
    "name": "cell44",
    "collapsed": false
   },
   "outputs": [],
   "source": "semantic_model_region = \"\"\"\n  - name: region\n    description: Region dimension table with unique region identifiers and geographic attributes.\n    base_table:\n      database: cortex_analyst_demo\n      schema: revenue_timeseries\n      table: region_dim\n    primary_key:\n      columns:\n        - region_id\n    dimensions:\n      - name: region_id\n        expr: region_id\n        data_type: number\n      - name: sales_region\n        expr: sales_region\n        description: Region associated with revenue\n        data_type: varchar\n        sample_values:\n          - North America\n          - Europe\n          - Asia\n          - South America\n          - Africa\n\"\"\"\n\nsemantic_model += semantic_model_region",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b94941ca-c4a6-4328-86ea-bb1e451f340a",
   "metadata": {
    "language": "python",
    "name": "cell34",
    "collapsed": false
   },
   "outputs": [],
   "source": "semantic_model_relationships = \"\"\"\nrelationships:\n  - name: revenue_to_region\n    left_table: daily_revenue\n    right_table: region\n    relationship_columns:\n      - left_column: region_id\n        right_column: region_id\n    join_type: left_outer\n    relationship_type: many_to_one\n\"\"\"\n\nsemantic_model += semantic_model_relationships",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d8ec4d49-2cee-452b-94d8-d4955b804dee",
   "metadata": {
    "language": "python",
    "name": "cell35",
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import Complete\n\nuser_query = \"What is the highest daily revenue recorded in a single day in each sales region?\"\n\nnaive_text_to_sql_messages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that writes snowflake SQL to answer natural language questions. Respond with only SQL'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'All tables are in the fully qualified snowflake schema: CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.'\n                       f'{semantic_model}'\n                       f'Please write valid snowflake SQL to answer the user question, and do not include fences.'\n        }\n    ]\n    \n\nsql = Complete(\"claude-3-5-sonnet\", naive_text_to_sql_messages)\n\nsql",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9595f1d6-7a98-449e-b10b-6eb3b296314b",
   "metadata": {
    "language": "python",
    "name": "cell45",
    "collapsed": false
   },
   "outputs": [],
   "source": "sql_output = session.sql(sql)\n\nsql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "84056c8b-905e-4302-9bd3-ee957d997288",
   "metadata": {
    "name": "cell36",
    "collapsed": false
   },
   "source": "Now that we've got a tougher task, even the SOTA LLM fails to generate valid SQL.\n\nLet's turn to Cortex Analyst using the same semantic model."
  },
  {
   "cell_type": "markdown",
   "id": "c4e16b63-4492-4ef4-aa83-92de7e99af3f",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "## Call Cortex Analyst\n\nFirst, we'll just show how to make the REST API call and return SQL"
  },
  {
   "cell_type": "code",
   "id": "5136e911-32e6-4b9b-b35c-6f2e129322b3",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import json\nimport requests\nfrom typing import List\nimport _snowflake\nfrom snowflake.snowpark.context import get_active_session\n\n# Change this to match your semantic model stage/path\nDEFAULT_SEMANTIC_MODEL = \"CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.RAW_DATA/revenue_timeseries.yaml\"\n\nAPI_ENDPOINT = \"/api/v2/cortex/analyst/message\"\nAPI_TIMEOUT = 50000  # in milliseconds\n\ndef get_sql_from_cortex_analyst(query: str) -> List[str]:\n    \"\"\"\n    Calls Cortex Analyst with the user's query and returns any generated SQL statements.\n    \n    Returns:\n        A list of SQL statements found in the Analyst's response (there can be more than one).\n    \"\"\"\n    # Build the message list (only one user message for simplicity).\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [{\"type\": \"text\", \"text\": query}],\n        }\n    ]\n    \n    # Build the request body\n    request_body = {\n        \"messages\": messages,\n        \"semantic_model\": semantic_model,\n    }\n    \n    # Make the request to the Analyst API\n    resp = _snowflake.send_snow_api_request(\n        \"POST\",  # method\n        API_ENDPOINT,  # path\n        {},  # headers\n        {},  # params\n        request_body,  # body\n        None,  # request_guid\n        API_TIMEOUT,  # timeout in milliseconds\n    )\n    \n    # Use resp.json() to get parsed JSON\n    parsed_content = json.loads(resp[\"content\"])\n\n    return parsed_content[\"message\"][\"content\"][1]\n\nuser_query = \"What is the highest daily revenue recorded in a single day in each sales region?\"\nanalyst_output = get_sql_from_cortex_analyst(user_query)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc8a72a2-553a-4938-b122-6a144e644397",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "analyst_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73b4e6cf-2733-46f1-ba48-9709fe061ffe",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "## Run the SQL\n\nNext, we can run the sql and save it to a variable"
  },
  {
   "cell_type": "code",
   "id": "ebbb6f6a-05db-48e3-aa42-9124b01bcbcb",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\n\nsql_output = session.sql(analyst_output['statement'])\n\nsql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b057e25e-d7b4-4084-b943-c02a47761d13",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "## Let's not stop at the table, and get to a natural language response\n\nPass SQL output to LLM-readable markdown\n\nNote: Make sure `tabulate` library is installed"
  },
  {
   "cell_type": "code",
   "id": "1e2ca41d-cbb3-4f65-b92f-41dd897a633a",
   "metadata": {
    "language": "python",
    "name": "cell20",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "markdown_sql_output = sql_output.to_pandas().to_markdown(index=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5daa4555-0e50-49c1-8f58-7bbb24bb920b",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "markdown_sql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69abba1-9785-4776-ae3e-636e515d6f05",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## Send the query and SQL output to the LLM"
  },
  {
   "cell_type": "code",
   "id": "65068655-7f77-4c94-9b5c-d4a162f3e90e",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import Complete\nimport pandas as pd\n\nmessages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that sql output to answer natural language questions.'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'The question has been translated into a SQL statement, executed, and the results are found in:'\n                       f'\\n{markdown_sql_output}'\n                       f'Please answer the user question.'\n        }\n    ]\n\noptions = {\n    'guardrails': True,\n}\n\nComplete(\"claude-3-5-sonnet\", messages, options = options)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ee93533-b6cd-4c5f-9d3f-085b39416064",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "## Put it together\n\nNow we have a single method that can answer questions from tabular data!"
  },
  {
   "cell_type": "code",
   "id": "53d4b1d1-729a-4b53-828b-ff01782db3ee",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def answer_question_using_analyst(query: str):\n    # use cortex analyst to generate sql for the query\n    analyst_output = get_sql_from_cortex_analyst(query)\n    # execute sql\n    sql_output = session.sql(analyst_output['statement'])\n    # make the output LLM-readable\n    markdown_sql_output = sql_output.to_pandas().to_markdown(index=False)\n    # send query and sql results to LLM\n    messages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that sql output to answer natural language questions.'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'The question has been translated into a SQL statement, executed, and the results are found in:'\n                       f'\\n{markdown_sql_output}'\n                       f'Please answer the user question.'\n        }\n    ]\n    \n    \n    options = {\n        'guardrails': True,\n    }\n\n    response = Complete(\"claude-3-5-sonnet\", messages, options = options)\n\n    return response",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f61fb90-c40c-4e04-8fc1-a3840993ba7a",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "answer_question_using_analyst(\"What is the highest daily revenue recorded in a single day in each sales region?\")",
   "execution_count": null
  }
 ]
}