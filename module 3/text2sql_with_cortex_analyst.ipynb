{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "5v6ontkg6xf5sjzbcbpz",
   "authorId": "273899124272",
   "authorName": "JREINI",
   "authorEmail": "josh.reini@snowflake.com",
   "sessionId": "e7f67937-3ec7-48d3-afad-55800f5fc726",
   "lastEditTime": 1737756154443
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6688ba9-a559-40ea-b801-c06e44499a1f",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "811e308b-0ee7-42d4-bd64-cb046f9e1d1c",
   "metadata": {
    "name": "cell8",
    "collapsed": false
   },
   "source": "# Build Text to SQL with Cortex Analyst\n\nIn this notebook we show how to build a text-to-sql app using Cortex Analyst."
  },
  {
   "cell_type": "markdown",
   "id": "a09186b0-9760-4da2-b69d-cedbe4fa514b",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "## Create the required roles to use Cortex Analyst\n\nMake sure to add your username in Line 10!"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1",
    "collapsed": false,
    "codeCollapsed": false
   },
   "source": "USE WAREHOUSE S;\n\nUSE ROLE SECURITYADMIN;\n\nCREATE OR REPLACE ROLE cortex_user_role;\nGRANT DATABASE ROLE SNOWFLAKE.CORTEX_USER TO ROLE cortex_user_role;\n\nUSE ROLE SECURITYADMIN;\n\nGRANT ROLE cortex_user_role TO USER <user>;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2142e1fc-9fe9-4d70-bad2-9f5dd5ec76e1",
   "metadata": {
    "name": "cell4",
    "collapsed": false
   },
   "source": "## Create the required databases, schemas and warehouse for this example"
  },
  {
   "cell_type": "code",
   "id": "4bb4abc2-9feb-4c23-adf8-ccd04883fa82",
   "metadata": {
    "language": "sql",
    "name": "cell6",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "USE ROLE ACCOUNTADMIN;\n\n-- Create demo database\nCREATE OR REPLACE DATABASE cortex_analyst_demo;\n\n-- Create schema\nCREATE OR REPLACE SCHEMA cortex_analyst_demo.revenue_timeseries;\n\n-- Create warehouse\nCREATE OR REPLACE WAREHOUSE cortex_analyst_wh\n    WAREHOUSE_SIZE = 'large'\n    WAREHOUSE_TYPE = 'standard'\n    AUTO_SUSPEND = 60\n    AUTO_RESUME = TRUE\n    INITIALLY_SUSPENDED = TRUE\nCOMMENT = 'Warehouse for Cortex Analyst demo';\n\nGRANT USAGE ON WAREHOUSE cortex_analyst_wh TO ROLE cortex_user_role;\nGRANT OPERATE ON WAREHOUSE cortex_analyst_wh TO ROLE cortex_user_role;\n\nGRANT OWNERSHIP ON SCHEMA cortex_analyst_demo.revenue_timeseries TO ROLE cortex_user_role;\nGRANT OWNERSHIP ON DATABASE cortex_analyst_demo TO ROLE cortex_user_role;\n\nUSE ROLE cortex_user_role;\n\n-- Use the created warehouse\nUSE WAREHOUSE cortex_analyst_wh;\n\nUSE DATABASE cortex_analyst_demo;\nUSE SCHEMA cortex_analyst_demo.revenue_timeseries;\n\n-- Create stage for raw data\nCREATE OR REPLACE STAGE raw_data DIRECTORY = (ENABLE = TRUE);\n\n/*--\n• Fact and Dimension Table Creation\n--*/\n\n-- Fact table: daily_revenue\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.daily_revenue (\n    date DATE,\n    revenue FLOAT,\n    cogs FLOAT,\n    forecasted_revenue FLOAT,\n    product_id INT,\n    region_id INT\n);\n\n-- Dimension table: product_dim\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.product_dim (\n    product_id INT,\n    product_line VARCHAR(16777216)\n);\n\n-- Dimension table: region_dim\nCREATE OR REPLACE TABLE cortex_analyst_demo.revenue_timeseries.region_dim (\n    region_id INT,\n    sales_region VARCHAR(16777216),\n    state VARCHAR(16777216)\n);",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef609d1e-66b4-41c9-bf5f-6b18abb17f41",
   "metadata": {
    "name": "cell2",
    "collapsed": false
   },
   "source": "There are three data files and one YAML file included in the this repository.\n\ndaily_revenue.csv\nregion.csv\nproduct.csv\nrevenue_timeseries.yaml\nYou will now upload these files to your Snowflake account and ingest the data files into the tables created in the previous step.\n\nTo upload the data files:\n\n1. Set your role to Cortex User Role\n2. Navigate to the Data tab in Snowsight, and select Add Data\n3. On the Add Data page, select Load files into a stage\n4. Select the four files that you want to upload (listed above)\n5. Select CORTEX_ANALYST_DEMO as Database, REVENUE_TIMESERIES as Schema, and RAW_DATA as Stage\n6. Click Upload\n\nLet's go check that the files were successfully uploaded to the stage. In the Snowsight UI:\n\n7. Select Data » Databases\n8. Select the CORTEX_ANALYST_DEMO database and REVENUE_TIMESERIES Schema that contain the stage\n9. Select Stages and select the RAW_DATA stage\n10. If prompted, select Enable Directory Table and the CORTEX_ANALYST_WH to refresh the directory table\n\nYou should see the four files listed in the stage."
  },
  {
   "cell_type": "markdown",
   "id": "1cb88089-b92d-4176-93ca-5d53b8673896",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "## Copy data from stage into tables"
  },
  {
   "cell_type": "code",
   "id": "35b3572a-da63-4f67-a889-536bdb71086f",
   "metadata": {
    "language": "sql",
    "name": "cell3",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "/*--\n• looad data into tables\n--*/\n\nUSE ROLE CORTEX_USER_ROLE;\nUSE DATABASE CORTEX_ANALYST_DEMO;\nUSE SCHEMA CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES;\nUSE WAREHOUSE CORTEX_ANALYST_WH;\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.DAILY_REVENUE\nFROM @raw_data\nFILES = ('daily_revenue.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n\n\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.PRODUCT_DIM\nFROM @raw_data\nFILES = ('product.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;\n\n\n\nCOPY INTO CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.REGION_DIM\nFROM @raw_data\nFILES = ('region.csv')\nFILE_FORMAT = (\n    TYPE=CSV,\n    SKIP_HEADER=1,\n    FIELD_DELIMITER=',',\n    TRIM_SPACE=FALSE,\n    FIELD_OPTIONALLY_ENCLOSED_BY=NONE,\n    REPLACE_INVALID_CHARACTERS=TRUE,\n    DATE_FORMAT=AUTO,\n    TIME_FORMAT=AUTO,\n    TIMESTAMP_FORMAT=AUTO\n    EMPTY_FIELD_AS_NULL = FALSE\n    error_on_column_count_mismatch=false\n)\n\nON_ERROR=CONTINUE\nFORCE = TRUE ;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "31322281-80ec-4143-b611-08df10dde463",
   "metadata": {
    "name": "cell10",
    "collapsed": false
   },
   "source": "## Create a Cortex Search service to help Analyst\n\nNow, you will integrate Cortex Search as a way to improve literal string searches to help Cortex Analyst generate more accurate SQL queries. Writing the correct SQL query to answer a question sometimes requires knowing exact literal values to filter on. Since those values can't always be extracted directly from the question, a search of some kind may be needed."
  },
  {
   "cell_type": "code",
   "id": "c67b082a-bdcb-4112-a93e-1a5cc6ce3604",
   "metadata": {
    "language": "sql",
    "name": "cell12",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "USE DATABASE cortex_analyst_demo;\nUSE SCHEMA revenue_timeseries;\nuse ROLE cortex_user_role;\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE product_line_search_service\n  ON product_dimension\n  WAREHOUSE = cortex_analyst_wh\n  TARGET_LAG = '1 hour'\n  AS (\n      SELECT DISTINCT product_line AS product_dimension FROM product_dim\n  );",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c4e16b63-4492-4ef4-aa83-92de7e99af3f",
   "metadata": {
    "name": "cell16",
    "collapsed": false
   },
   "source": "## Call Cortex Analyst\n\nFirst, we'll just show how to make the REST API call and return SQL"
  },
  {
   "cell_type": "code",
   "id": "5136e911-32e6-4b9b-b35c-6f2e129322b3",
   "metadata": {
    "language": "python",
    "name": "cell13",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import json\nimport requests\nfrom typing import List\nimport _snowflake\nfrom snowflake.snowpark.context import get_active_session\n\n# Change this to match your semantic model stage/path\nDEFAULT_SEMANTIC_MODEL = \"CORTEX_ANALYST_DEMO.REVENUE_TIMESERIES.RAW_DATA/revenue_timeseries.yaml\"\n\nAPI_ENDPOINT = \"/api/v2/cortex/analyst/message\"\nAPI_TIMEOUT = 50000  # in milliseconds\n\ndef get_sql_from_cortex_analyst(query: str) -> List[str]:\n    \"\"\"\n    Calls Cortex Analyst with the user's query and returns any generated SQL statements.\n    \n    Returns:\n        A list of SQL statements found in the Analyst's response (there can be more than one).\n    \"\"\"\n    # Build the message list (only one user message for simplicity).\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [{\"type\": \"text\", \"text\": query}],\n        }\n    ]\n    \n    # Build the request body\n    request_body = {\n        \"messages\": messages,\n        \"semantic_model_file\": f\"@{DEFAULT_SEMANTIC_MODEL}\",\n    }\n    \n    # Make the request to the Analyst API\n    resp = _snowflake.send_snow_api_request(\n        \"POST\",  # method\n        API_ENDPOINT,  # path\n        {},  # headers\n        {},  # params\n        request_body,  # body\n        None,  # request_guid\n        API_TIMEOUT,  # timeout in milliseconds\n    )\n    \n    # Use resp.json() to get parsed JSON\n    parsed_content = json.loads(resp[\"content\"])\n\n    return parsed_content[\"message\"][\"content\"][1][\"statement\"]\n\nuser_query = \"what is the highest revenue recorded in a single day? which day?\"\nsql = get_sql_from_cortex_analyst(user_query)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bc8a72a2-553a-4938-b122-6a144e644397",
   "metadata": {
    "language": "python",
    "name": "cell18",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "sql",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "73b4e6cf-2733-46f1-ba48-9709fe061ffe",
   "metadata": {
    "name": "cell11",
    "collapsed": false
   },
   "source": "## Run the SQL\n\nNext, we can run the sql and save it to a variable"
  },
  {
   "cell_type": "code",
   "id": "ebbb6f6a-05db-48e3-aa42-9124b01bcbcb",
   "metadata": {
    "language": "python",
    "name": "cell15",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "session = get_active_session()\n\nsql_output = session.sql(sql)\n\nsql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b057e25e-d7b4-4084-b943-c02a47761d13",
   "metadata": {
    "name": "cell19",
    "collapsed": false
   },
   "source": "## Pass SQL output to LLM-readable markdown\n\nMake sure `tabulate` library is installed"
  },
  {
   "cell_type": "code",
   "id": "1e2ca41d-cbb3-4f65-b92f-41dd897a633a",
   "metadata": {
    "language": "python",
    "name": "cell20",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "markdown_sql_output = sql_output.to_pandas().to_markdown(index=False)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5daa4555-0e50-49c1-8f58-7bbb24bb920b",
   "metadata": {
    "language": "python",
    "name": "cell21",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "markdown_sql_output",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a69abba1-9785-4776-ae3e-636e515d6f05",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## Send the query and SQL output to the LLM"
  },
  {
   "cell_type": "code",
   "id": "65068655-7f77-4c94-9b5c-d4a162f3e90e",
   "metadata": {
    "language": "python",
    "name": "cell17",
    "codeCollapsed": false,
    "collapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import Complete\nimport pandas as pd\n\nmessages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that sql output to answer natural language questions.'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'The question has been translated into a SQL statement, executed, and the results are found in:'\n                       f'\\n{markdown_sql_output}'\n                       f'Please answer the user question.'\n        }\n    ]\n\noptions = {\n    'guardrails': True,\n}\n\nComplete(\"claude-3-5-sonnet\", messages, options = options)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0ee93533-b6cd-4c5f-9d3f-085b39416064",
   "metadata": {
    "name": "cell14",
    "collapsed": false
   },
   "source": "## Put it together"
  },
  {
   "cell_type": "code",
   "id": "53d4b1d1-729a-4b53-828b-ff01782db3ee",
   "metadata": {
    "language": "python",
    "name": "cell23",
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def answer_question_using_analyst(query: str):\n    # use cortex analyst to generate sql for the query\n    sql = get_sql_from_cortex_analyst(query)\n    # execute sql\n    sql_output = session.sql(sql)\n    # make the output LLM-readable\n    markdown_sql_output = sql_output.to_pandas().to_markdown(index=False)\n    # send query and sql results to LLM\n    messages = [\n        {\n            'role': 'system',\n            'content': 'You are a helpful assistant that sql output to answer natural language questions.'\n        },\n        {\n            'role': 'user',\n            'content': f'The user has posed a question, which is captured in: {user_query}. '\n                       f'The question has been translated into a SQL statement, executed, and the results are found in:'\n                       f'\\n{markdown_sql_output}'\n                       f'Please answer the user question.'\n        }\n    ]\n    \n    \n    options = {\n        'guardrails': True,\n    }\n\n    response = Complete(\"claude-3-5-sonnet\", messages, options = options)\n\n    return response",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4f61fb90-c40c-4e04-8fc1-a3840993ba7a",
   "metadata": {
    "language": "python",
    "name": "cell24",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "answer_question_using_analyst(\"what is the highest revenue recorded in a single day? which day?\")",
   "execution_count": null
  }
 ]
}